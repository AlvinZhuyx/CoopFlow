# CoopFlow
Cooperative learning of Langevin Flow (short-run MCMC) and Normalizing Flow

This repository contains a pytorch implementation for ICLR 2022 paper "[A Tale of Two Flows: Cooperative Learning of Langevin Flow and Normalizing Flow Toward Energy-Based Model](https://openreview.net/forum?id=31d5RLCUuXC&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2022%2FConference%2FAuthors%23your-submissions))"

For the implementation of pytorch Flow++ model, we adapt the code from "[this github link](https://github.com/chrischute/flowplusplus)".

## Set Up Environment
We have provided the environment.yml file for setting up the environment. The environment can be set up with one command using conda

```bash
conda env create -f environment.yml
conda activate fpp
```

## Exp 1: Image synthesis with pretrained models
1. To generate images using pretrained models, please first download the pretrained checkpoints from "[this link](https://drive.google.com/drive/folders/1NY5NA7wIguuGEnH4jo-vQ4f4fxFyC-58?usp=sharing)". The folder contains checkpoints with different experimental settings. Please check the Readme file for detailed descriptions. The checkpoints should be downloaded to the ckpt folder (e.g., you should have 'ckpt/cifar10.pth.tar' for CoopFlow cifar10 setting).

2. After the checkpoint is downloaded, you can perform image synthesis using files 'main_\*.py'. Each individual code corresponds to a different dataset. The *main_cifar.py, main_celeba.py, main_svhn.py* are codes for basic CoopFlow setting. The *main_cifar_pretrain.py main_celeba_pretrain.py, main_svhn_pretrain.py* are codes for CoopFlow(Pre) setting. For CoopFlow(Long) setting, we use multi-gpu for training and the code will come later.  

For example, if you want to synthesize images using pretrained CoopFlow model on cifar10 dataset. You can symply run
```bash
python main_cifar.py
```

3. Compute FID: The code save generated images (The number of synthesized images is 50,000 in total) in the folder './exp_cifar/gen_samples' and original images to './exp_cifar/ori_samples'. Then you can use "[pytorch_fid](https://github.com/mseitzer/pytorch-fid)" to calculate the FID score. For example, you can use the following command
```bash
python -m pytorch_fid ./exp_cifar/ori_samples ./exp_cifar/gen_samples
```

4. The following are synthesized examples under CoopFlow (T=30) setting. Please refer to the paper for more results.

**Cifar-10** (Left: initial proposal generated by normalizing flow; Right: modified examples by Langevin flow) 

<img src="/images/cifar_flow.png" width="300"/> <img src="/images/Cifar10.png" width="300"/> 

**svhn** (Left: initial proposal generated by normalizing flow; Right: modified examples by Langevin flow) 

<img src="/images/SVHN_flow35.png" width="300"/> <img src="/images/SVHN.png" width="300"/>

**Celeba** (Left: initial proposal generated by normalizing flow; Right: modified examples by Langevin flow) 

<img src="/images/Celeba_flow44.png" width="300"/> <img src="/images/Celeba32.png" width="300"/>


## Exp 2: Retrain the models
To train the model, you can run 'main_\*.py' with the training mode, for example:
```bash
python main_cifar.py --train True --resume False --batch_size 28 --step_size 0.03
```
In most setting of our experiments, we use a single nvidia A100 GPU, which has 40GB memory and we set the batch size to 28 during training. The training takes about 6 days. You may try to reduce the batch size if the memory is not enough on your case. Or you may try the multi-gpu version code (**coming soon**).
Note that some hyperparameters (like the MCMC step size) might be different during training and image synthesizing, please refer to Section A.2 in our paper for the detailed training hyperparameters in each experiment.

If you want to train the model in CoopFlow(pre) setting. You need a pretrained flow++ model first. You can train the flow model using the [code here](https://github.com/chrischute/flowplusplus). We also provide our pretrained flow++ model [here](https://drive.google.com/drive/folders/1NY5NA7wIguuGEnH4jo-vQ4f4fxFyC-58?usp=sharing). You can download the corresponding **pretrained flow++ checkpoint** (in the pretrain_flow_ckpt folder on the dirve) to the flow_ckpt folder (e.g. './flow_ckpt/cifar10.pth.tar'). Then  (take cifar10 as an example) simply run
```bash
python main_cifar_pretrain.py --train True --resume False --batch_size 28 --step_size 0.03
```



## Exp 3: Other testing experiments
**Image reconstruction**

To reproduce the image reconstruction results on cifar10 with pre-trained CoopFlow model in section 5.3. Please first download the checkpoint to folder ckpt ('ckpt/cifar10.pth.tar'), then run the following command
```bash
python test_recons.py
```

**Image impainting**

To reproduce the image impainting results on celeba with pre-trained CoopFlow model in section 5.3. Please first download the checkpoint to folder ckpt ('ckpt/celeba.pth.tar'), then run the following command
```bash
python test_impaint.py
```

**Image interpolation**

To reproduce the image interpolation results on celeba with pre-trained CoopFlow model in section 5.4. Please first download the checkpoint to folder ckpt ('ckpt/celeba.pth.tar'), then run the following command
```bash
python test_interp.py
```

